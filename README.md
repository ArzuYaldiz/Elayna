In today's fast-paced world, choosing daily outfits can often feel like a time-consuming and exhausting task, especially for individuals with physical limitations or busy lifestyles. This thesis presents the design and development of a mobile application that allows users to virtually try on clothes and receive outfit combination suggestions using augmented reality (AR) and machine learning technologies. The application enables users to upload photos of their clothing, which are then transformed into 3D models and mapped onto the userâ€™s body using real-time body tracking. Personalized outfit suggestions are generated based on the user's wardrobe, preferences, and contextual data such as weather conditions.

The project was inspired by a real-life event when one of the team members faced difficulty getting dressed due to a temporary disability. This experience shaped the motivation behind creating a tool that is accessible, practical, and inclusive for all users. By eliminating the physical need to try on clothes, the application aims to reduce decision fatigue, enhance fashion creativity, and help users rediscover forgotten pieces in their wardrobes. The system is implemented using Unity for AR capabilities, Python and TensorFlow for AI-based recommendation logic, and Android Studio for the front end. This work demonstrates that technology can effectively improve everyday routines and offer inclusive solutions in the fashion and clothing sector.
